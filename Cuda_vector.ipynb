{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Umesh9045/LP5/blob/main/Cuda_vector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VtdGdFQc7Ml",
        "outputId": "c7f85d14-3409-41cf-914e-08be62e65a53"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-q3_qqszd\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-q3_qqszd\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 5741c522547756ac4bb7a16df32106a15efb8a57\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: nvcc4jupyter\n",
            "  Building wheel for nvcc4jupyter (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvcc4jupyter: filename=nvcc4jupyter-1.2.1-py3-none-any.whl size=10741 sha256=1c43b610d84440f376c57bb0b3d20f87e2433fdb6f06eb98d5fd7c81c461a971\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-yqzdc65d/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built nvcc4jupyter\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "id": "0hh1WyesdNZu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "472812cc-f3db-4897-e414-24cb5ea81a19"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgVtVI-1FBTA",
        "outputId": "75c404ad-6d18-4a42-a7d1-ae589ab75bdb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nvcc4jupyter in /usr/local/lib/python3.10/dist-packages (1.2.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXxwwuRqFNNc",
        "outputId": "3ab0fb48-6902-486d-af09-3d304fe49133"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected platform \"Colab\". Running its setup...\n",
            "Source files will be saved in \"/tmp/tmpcl34nxvn\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "555CvktCFcE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "#define HANDLE_ERROR( err ) ( HandleError( err, __FILE__, __LINE__ ) )\n",
        "\n",
        "static void HandleError( cudaError_t err, const char *file, int line )\n",
        "{\n",
        "    if (err != cudaSuccess)\n",
        "      {\n",
        "        printf( \"%s in %s at line %d\\n\", cudaGetErrorString( err ),\n",
        "                file, line );\n",
        "        exit( EXIT_FAILURE );\n",
        "    }\n",
        "}\n",
        "\n",
        "const short N = 5 ;\n",
        "\n",
        "__global__ void Vector_Addition ( const int *dev_a , const int *dev_b , int *dev_c)\n",
        "{\n",
        "      unsigned short tid = threadIdx.x ;\n",
        "\n",
        "      if ( tid < N )\n",
        "            dev_c [tid] = dev_a[tid] + dev_b[tid] ;\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "int main (void)\n",
        "{\n",
        "      int Host_a[N], Host_b[N], Host_c[N];\n",
        "\n",
        "\n",
        "      int *dev_a , *dev_b, *dev_c ;\n",
        "\n",
        "\n",
        "      HANDLE_ERROR ( cudaMalloc((void **)&dev_a , N*sizeof(int) ) );\n",
        "      HANDLE_ERROR ( cudaMalloc((void **)&dev_b , N*sizeof(int) ) );\n",
        "      HANDLE_ERROR ( cudaMalloc((void **)&dev_c , N*sizeof(int) ) );\n",
        "\n",
        "\n",
        "      for ( int i = 0; i <N ; i++ )\n",
        "      {\n",
        "            Host_a[i] = i ;\n",
        "            Host_b[i] = i*i ;\n",
        "      }\n",
        "\n",
        "      HANDLE_ERROR (cudaMemcpy (dev_a , Host_a , N*sizeof(int) , cudaMemcpyHostToDevice));\n",
        "      HANDLE_ERROR (cudaMemcpy (dev_b , Host_b , N*sizeof(int) , cudaMemcpyHostToDevice));\n",
        "\n",
        "      Vector_Addition <<< 1, N  >>> (dev_a , dev_b , dev_c ) ;\n",
        "\n",
        "      HANDLE_ERROR (cudaMemcpy(Host_c , dev_c , N*sizeof(int) , cudaMemcpyDeviceToHost));\n",
        "\n",
        "      for ( int i = 0; i<N; i++ )\n",
        "                  printf (\"%d + %d = %d\\n\", Host_a[i] , Host_b[i] , Host_c[i] ) ;\n",
        "\n",
        "      cudaFree (dev_a) ;\n",
        "      cudaFree (dev_b) ;\n",
        "      cudaFree (dev_c) ;\n",
        "\n",
        "      system(\"pause\");\n",
        "      return 0 ;\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "1bMukendcVUR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e55cc01b-52db-42ff-ccde-a5937b9f55c7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sh: 1: pause: not found\n",
            "0 + 0 = 0\n",
            "1 + 1 = 2\n",
            "2 + 4 = 6\n",
            "3 + 9 = 12\n",
            "4 + 16 = 20\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "%%cuda\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "#define HANDLE_ERROR( err ) ( HandleError( err, __FILE__, __LINE__ ) )\n",
        "static void HandleError( cudaError_t err, const char *file, int line )\n",
        "{\n",
        "    if (err != cudaSuccess)\n",
        "      {\n",
        "        printf( \"%s in %s at line %d\\n\", cudaGetErrorString( err ),\n",
        "                file, line );\n",
        "        exit( EXIT_FAILURE );\n",
        "    }\n",
        "}\n",
        "\n",
        "# Size of arrays\n",
        "const short N = 5 ;\n",
        "\n",
        "# Function takes three parameters:\n",
        "# dev_a: Pointer to the first input array.\n",
        "# dev_b: Pointer to the second input array.\n",
        "# dev_c: Pointer to the output array.\n",
        "__global__ void Vector_Addition ( const int *dev_a , const int *dev_b , int *dev_c)\n",
        "{\n",
        "    #  calculates the thread index and stores in variable 'tid'\n",
        "      unsigned short tid = threadIdx.x ;\n",
        "\n",
        "      if ( tid < N )\n",
        "            dev_c [tid] = dev_a[tid] + dev_b[tid] ;\n",
        "}\n",
        "\n",
        "\n",
        "int main (void)\n",
        "{\n",
        "      # Host vectors to store input vectors a, b, and output vector c\n",
        "      int Host_a[N], Host_b[N], Host_c[N];\n",
        "\n",
        "      # device pointer for device vectors\n",
        "      int *dev_a , *dev_b, *dev_c ;\n",
        "\n",
        "      #  Allocate memory on GPU dor device vector\n",
        "      HANDLE_ERROR ( cudaMalloc((void **)&dev_a , N*sizeof(int) ) );\n",
        "      HANDLE_ERROR ( cudaMalloc((void **)&dev_b , N*sizeof(int) ) );\n",
        "      HANDLE_ERROR ( cudaMalloc((void **)&dev_c , N*sizeof(int) ) );\n",
        "\n",
        "      # Initialize host arrays with values\n",
        "      for ( int i = 0; i <N ; i++ )\n",
        "      {\n",
        "            Host_a[i] = i ;\n",
        "            Host_b[i] = i*i ;\n",
        "      }\n",
        "\n",
        "      # Copy data from host to device\n",
        "      HANDLE_ERROR (cudaMemcpy (dev_a , Host_a , N*sizeof(int) , cudaMemcpyHostToDevice));\n",
        "      HANDLE_ERROR (cudaMemcpy (dev_b , Host_b , N*sizeof(int) , cudaMemcpyHostToDevice));\n",
        "\n",
        "      # Launch kernel function 'vectorAdd' with one block containing 'N' threads.\n",
        "      Vector_Addition <<< 1, N  >>> (dev_a , dev_b , dev_c ) ;\n",
        "\n",
        "      # Copy result from device to host\n",
        "      HANDLE_ERROR (cudaMemcpy(Host_c , dev_c , N*sizeof(int) , cudaMemcpyDeviceToHost));\n",
        "\n",
        "      # Print result\n",
        "      for ( int i = 0; i<N; i++ )\n",
        "                  printf (\"%d + %d = %d\\n\", Host_a[i] , Host_b[i] , Host_c[i] ) ;\n",
        "\n",
        "      # Free device memory\n",
        "      cudaFree (dev_a) ;\n",
        "      cudaFree (dev_b) ;\n",
        "      cudaFree (dev_c) ;\n",
        "\n",
        "      system(\"pause\");\n",
        "      return 0 ;\n",
        "\n",
        "}\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "uQJKTrfJ6rfs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a **CUDA** program:\n",
        "- The **main computer (CPU)** prepares the task and the data.\n",
        "- It sends the data to the **graphics card (GPU)** for processing.\n",
        "- The GPU does the heavy lifting, like adding big numbers together quickly.\n",
        "- After finishing, the GPU sends the result back to the main computer.\n",
        "- The main computer stores the result and can use it for further tasks.\n"
      ],
      "metadata": {
        "id": "EX4cE5fJ-e9G"
      }
    }
  ]
}